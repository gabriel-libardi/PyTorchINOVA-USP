{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/gabriel-libardi/PyTorchINOVA-USP/blob/main/Zurique.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Dataset\n"
      ],
      "metadata": {
        "id": "4Q_9qin-oO0w"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Baixar e descompactar o dataset\n",
        "!wget -q \"https://docs.toradex.com/private/114105-recyclables_train.zip​\"\n",
        "!wget -q \"https://docs.toradex.com/private/114106-recyclables_validation.zip\"\n",
        "#!unzip -q '114105-recyclables_train.zip' -d dataset/\n",
        "\n",
        "# Definir o caminho do dataset\n",
        "# data_path = \"dataset\""
      ],
      "metadata": {
        "id": "EFJVWj9s5SFF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip -q '114105-recyclables_train.zip' -d dataset/"
      ],
      "metadata": {
        "id": "4Jqggl2QEOKs",
        "outputId": "7cbc8a4b-3691-4e5f-cf1b-a7b3f5d3ee40",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "unzip:  cannot find or open 114105-recyclables_train.zip, 114105-recyclables_train.zip.zip or 114105-recyclables_train.zip.ZIP.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Importar dependências"
      ],
      "metadata": {
        "id": "BLPH1fOIoRmg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Carregar a extensão do TensorBoard para o Google Colab\n",
        "%load_ext tensorboard\n",
        "\n",
        "# Instalar Pytorch, Torchvision, Tensorboard e utilidades parar ver o progresso do treinamento\n",
        "!pip install -q torch torchvision torcheval tensorboard matplotlib tqdm tensorflow ipywidgets seaborn\n",
        "\n",
        "# Módulos, classes e funções que são úteis para inferência e treinamento\n",
        "import torch, torchvision\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torchvision import transforms\n",
        "from torchvision.io import read_image\n",
        "from torcheval.metrics import MulticlassF1Score, MulticlassRecall, MulticlassPrecision\n",
        "\n",
        "# Suporte a TensorBoard no PyTorch\n",
        "from torch.utils.tensorboard import SummaryWriter\n",
        "\n",
        "# Utiliades do sistema\n",
        "from datetime import datetime\n",
        "import time\n",
        "import os\n",
        "\n",
        "# O Tqdm é utilizado para criar barras de progresso\n",
        "from tqdm.notebook import tqdm\n",
        "\n",
        "\n",
        "print(torch.__version__)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G3uSnPVwoUlB",
        "outputId": "f5b37ed5-abdf-4aee-a49d-3ca4f4575d3e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m179.2/179.2 kB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m11.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h2.1.0+cu118\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Customização do dataset"
      ],
      "metadata": {
        "id": "-92E5RIzoi2g"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Declaração da classe herdando de Dataset\n",
        "class CustomDataset(Dataset):\n",
        "\n",
        "    # Construtor\n",
        "    def __init__(self, images_dir, preprocess_function):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            images_dir (string): Directory with all the image folders\n",
        "            preprocess_function (callable): Transform to be applied on a sample\n",
        "        \"\"\"\n",
        "\n",
        "        self.images_dir = images_dir\n",
        "        self.transform = preprocess_function\n",
        "\n",
        "        # Ordenamos as classes para termos sempre a mesma ordem\n",
        "        # Aqui ficam armazenados os nomes de cada classe\n",
        "        self.classes = sorted(os.listdir(self.images_dir))\n",
        "\n",
        "        # Caminho para cada imagem\n",
        "        self.image_paths = []\n",
        "        # Classe de cada imagem (int)\n",
        "        self.image_classes = []\n",
        "\n",
        "        # Procura imagens para todas as classes, em suas respectivas pastas\n",
        "        for i in range(0, len(self.classes)):\n",
        "          sample_class = self.classes[i]\n",
        "\n",
        "          class_dir = os.path.join(self.images_dir, sample_class)\n",
        "          class_images = os.listdir(class_dir)\n",
        "\n",
        "          for image in class_images:\n",
        "            if(not (image.endswith(\".jpg\") or image.endswith(\".JPG\") or image.endswith(\".png\") or image.endswith(\".PNG\"))):\n",
        "                continue\n",
        "            image_path = os.path.join(class_dir, image)\n",
        "            self.image_paths.append(image_path)\n",
        "            self.image_classes.append(i)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.image_paths)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        if torch.is_tensor(idx):\n",
        "            idx = idx.tolist()\n",
        "\n",
        "        # Checagem por erros na leitura da imagem\n",
        "        # Isso gera uma nova excessão para que o dataset seja corrigido, não queremos imagens com problemas no dataset\n",
        "        try:\n",
        "            sample = read_image(self.image_paths[idx], torchvision.io.ImageReadMode.RGB)\n",
        "        except:\n",
        "            print(f\"Problem loading image {self.image_paths[idx]}\")\n",
        "            raise Exception()\n",
        "\n",
        "        # Preprocessamento da imagem\n",
        "        sample = self.transform(sample)\n",
        "\n",
        "        # Retorno do par (imagem, classe)\n",
        "        return sample, self.image_classes[idx]"
      ],
      "metadata": {
        "id": "Vb6D5sR_od7A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Pré-processamento\n",
        "\n",
        "**OBS.: TESTAR TAMANHOS DE INFERENCE_SIZE DIFERENTES (IMPACTA TEMPO DE EXECUÇÃO) **"
      ],
      "metadata": {
        "id": "ZmiJw-_1ouYH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 4\n",
        "inference_size = 50\n",
        "NormalizationMean = [0.485, 0.456, 0.406]\n",
        "NormalizationStd = [0.229, 0.224, 0.225]\n",
        "\n",
        "preprocess_image = transforms.Compose([\n",
        "    transforms.Resize((inference_size, inference_size), antialias=True),\n",
        "    transforms.ConvertImageDtype(torch.float),\n",
        "    transforms.Normalize(mean=NormalizationMean, std=NormalizationStd),\n",
        "])"
      ],
      "metadata": {
        "id": "HlYMFdC7owo_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Instanciamento dos datasets"
      ],
      "metadata": {
        "id": "5_Jt9txzpVwm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_data_path = os.path.join(data_path, \"train_crops\")\n",
        "validation_data_path = os.path.join(data_path, \"validation_crops\")"
      ],
      "metadata": {
        "id": "gLfQpYnwpZY2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset = CustomDataset(train_data_path, preprocess_image)\n",
        "validation_dataset = CustomDataset(validation_data_path, preprocess_image)\n",
        "\n",
        "train_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=1)\n",
        "validation_dataloader = DataLoader(validation_dataset, batch_size=batch_size, shuffle=True, num_workers=1)\n",
        "\n",
        "print( \"Train dataset information:\")\n",
        "print(f\" |-> Path:          {train_data_path}\")\n",
        "print(f\" |-> Length:        {len(train_dataset)}\")\n",
        "print(f\" '-> Loader length: {len(train_dataloader)}\")\n",
        "\n",
        "print( \"Validation dataset information:\")\n",
        "print(f\" |-> Path:          {validation_data_path}\")\n",
        "print(f\" |-> Length:        {len(validation_dataset)}\")\n",
        "print(f\" '-> Loader length: {len(validation_dataloader)}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 366
        },
        "id": "rGy7qpKKpo9F",
        "outputId": "d2a25c3d-dced-4ef7-9446-956d80d33790"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-6-db7b65e5465e>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain_dataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCustomDataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_data_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpreprocess_image\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mvalidation_dataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCustomDataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalidation_data_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpreprocess_image\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mtrain_dataloader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDataLoader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_dataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_workers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mvalidation_dataloader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDataLoader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalidation_dataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_workers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-3-2de597b1430c>\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, images_dir, preprocess_function)\u001b[0m\n\u001b[1;32m     15\u001b[0m         \u001b[0;31m# Ordenamos as classes para termos sempre a mesma ordem\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m         \u001b[0;31m# Aqui ficam armazenados os nomes de cada classe\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclasses\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msorted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimages_dir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m         \u001b[0;31m# Caminho para cada imagem\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'dataset2/dataset2/train_crops'"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Carregar o modelo\n",
        "\n",
        "OBS.: TESTAR DIFERENTES MODELOS"
      ],
      "metadata": {
        "id": "uKFIj34Zv_GR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# model = torch.hub.load('pytorch/vision:v0.10.0', 'resnet18', weights=torchvision.models.ResNet18_Weights.DEFAULT)\n",
        "# model = torch.hub.load('pytorch/vision:v0.10.0', 'resnet34', weights=torchvision.models.ResNet34_Weights.DEFAULT)\n",
        "model = torch.hub.load('pytorch/vision:v0.10.0', 'resnet50', weights=torchvision.models.ResNet50_Weights.DEFAULT)\n",
        "# model = torch.hub.load('pytorch/vision:v0.10.0', 'resnet101', weights=torchvision.models.ResNet101_Weights.DEFAULT)\n",
        "# model = torch.hub.load('pytorch/vision:v0.10.0', 'resnet152', weights=torchvision.models.ResNet152_Weights.DEFAULT)\n",
        "model.eval();"
      ],
      "metadata": {
        "id": "CctLArz-wBDC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%tensorboard --logdir runs"
      ],
      "metadata": {
        "id": "NKUhrCPawPAM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Treinamento por época"
      ],
      "metadata": {
        "id": "WBUvQGr4wkLL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def train_one_epoch(model, dataloader, optimizer, loss_function, epoch_index, device, tensorboard_writer):\n",
        "    running_loss = 0.0\n",
        "    last_loss = 0.0\n",
        "\n",
        "    model.to(device)\n",
        "\n",
        "    # Here, we use enumerate(training_loader) instead of\n",
        "    # iter(training_loader) so that we can track the batch\n",
        "    # index and do some intra-epoch reporting\n",
        "    print(f\"Training Epoch {epoch_index}:\")\n",
        "\n",
        "    progress_bar = tqdm(total=len(dataloader))\n",
        "    for i, data in enumerate(dataloader):\n",
        "\n",
        "        # Every data instance is an input + label pair\n",
        "        inputs, labels = data\n",
        "\n",
        "        inputs = inputs.to(device)\n",
        "        labels = labels.to(device)\n",
        "\n",
        "        # Zero gradients for every batch\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # Run Inference on the training data\n",
        "        outputs = model(inputs)\n",
        "\n",
        "        # Compute the loss and its gradients\n",
        "        loss = loss_function(outputs, labels)\n",
        "        loss.backward()\n",
        "\n",
        "        # Adjust learning weights\n",
        "        optimizer.step()\n",
        "\n",
        "        # Gather data and report\n",
        "        running_loss += loss.item()\n",
        "        if i % 10 == 9:\n",
        "            last_loss = running_loss / 10 # loss per batch\n",
        "            tb_x = (epoch_index*len(train_dataloader)) + i\n",
        "            tensorboard_writer.add_scalar('Loss/train', last_loss, tb_x)\n",
        "            tensorboard_writer.flush()\n",
        "            running_loss = 0.0\n",
        "\n",
        "        del inputs, labels\n",
        "\n",
        "        progress_bar.update(1)\n",
        "    return last_loss"
      ],
      "metadata": {
        "id": "vGN17GjhwcBZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')\n",
        "tensorboard_writer = SummaryWriter(f'runs/model_{timestamp}')\n",
        "\n",
        "EPOCHS = 1\n",
        "\n",
        "best_validation_loss = -1\n",
        "\n",
        "loss_function = torch.nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=0.001, momentum=0.9)\n",
        "\n",
        "device = 'cpu'\n",
        "if(torch.cuda.is_available()):\n",
        "    device = 'cuda'\n",
        "\n",
        "for epoch in range(EPOCHS):\n",
        "    print(f'EPOCH {epoch}:')\n",
        "\n",
        "    # Make sure gradient tracking is on, and do a pass over the data\n",
        "    model.train(True)\n",
        "    avg_loss = train_one_epoch(model, train_dataloader, optimizer, loss_function, epoch, device, tensorboard_writer)\n",
        "\n",
        "    running_validation_loss = 0.0\n",
        "    # Set the model to evaluation mode, disabling dropout and using population\n",
        "    # statistics for batch normalization.\n",
        "    model.eval()\n",
        "\n",
        "    model.to(device)\n",
        "\n",
        "    precision_metric = MulticlassPrecision(average='weighted', num_classes=len(validation_dataset.classes))\n",
        "    recall_metric = MulticlassRecall(average='weighted', num_classes=len(validation_dataset.classes))\n",
        "    f1score_metric = MulticlassF1Score(average='weighted', num_classes=len(validation_dataset.classes))\n",
        "\n",
        "    # Disable gradient computation and reduce memory consumption.\n",
        "    print(f\"Running Validation for Epoch {epoch}\")\n",
        "    with torch.no_grad():\n",
        "        progress_bar = tqdm(total=len(validation_dataloader))\n",
        "        for validation_data in validation_dataloader:\n",
        "            validation_inputs, validation_labels = validation_data\n",
        "            validation_inputs = validation_inputs.to(device)\n",
        "            validation_labels = validation_labels.to(device)\n",
        "            validation_outputs = model(validation_inputs)\n",
        "            running_validation_loss += loss_function(validation_outputs, validation_labels)\n",
        "\n",
        "            output_labels = []\n",
        "\n",
        "            for j in range(0, validation_outputs.size()[0]):\n",
        "                probabilities = torch.nn.functional.softmax(validation_outputs[j], dim=0)\n",
        "                prob, det_class = torch.topk(probabilities, 1)\n",
        "                # If the detected class is outside of bounds, give a wrong result within bounds\n",
        "                if(det_class >= len(validation_dataset.classes)):\n",
        "                    det_class = validation_labels[j].item()-1\n",
        "                    if(det_class < 0):\n",
        "                        det_class = validation_labels[j].item()+1\n",
        "                output_labels.append(det_class)\n",
        "\n",
        "            output_labels = torch.as_tensor(output_labels)\n",
        "            output_labels.to(device)\n",
        "\n",
        "            precision_metric.update(output_labels, validation_labels)\n",
        "            recall_metric.update(output_labels, validation_labels)\n",
        "            f1score_metric.update(output_labels, validation_labels)\n",
        "\n",
        "            del validation_inputs, validation_labels, output_labels\n",
        "\n",
        "            progress_bar.update(1)\n",
        "\n",
        "    precision = precision_metric.compute().item()\n",
        "    recall = recall_metric.compute().item()\n",
        "    f1score = f1score_metric.compute().item()\n",
        "\n",
        "    average_validation_loss = running_validation_loss / len(validation_dataloader)\n",
        "\n",
        "    # Log the running loss averaged per batch\n",
        "    # for both training and validation\n",
        "    tensorboard_writer.add_scalars('Training vs. Validation Loss',\n",
        "                                  { 'Training': avg_loss,\n",
        "                                    'Validation': average_validation_loss},\n",
        "                                    epoch)\n",
        "\n",
        "    tensorboard_writer.add_scalars('Validation Metrics',\n",
        "                                  { 'Precision': precision,\n",
        "                                    'Recall': recall,\n",
        "                                    'F1 Score': f1score},\n",
        "                                    epoch)\n",
        "    tensorboard_writer.flush()\n",
        "\n",
        "    tensorboard_writer.add_scalars('Learning Rate',\n",
        "                                  {'lr': optimizer.state_dict()['param_groups'][0]['lr']},\n",
        "                                    epoch)\n",
        "    tensorboard_writer.flush()\n",
        "\n",
        "    # Track best performance, and save the model's state\n",
        "    if((average_validation_loss < best_validation_loss) or (best_validation_loss == -1)):\n",
        "        best_validation_loss = average_validation_loss\n",
        "        torch.save(model.state_dict(), f'model_{timestamp}_best')\n",
        "\n",
        "    torch.save(model.state_dict(), f'model_{timestamp}_{epoch}')"
      ],
      "metadata": {
        "id": "ib97xtG8xN64"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Validação do modelo"
      ],
      "metadata": {
        "id": "3vf7WWPW3UEH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import math\n",
        "import matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sn\n",
        "import pandas as pd\n",
        "from torcheval.metrics import MulticlassConfusionMatrix\n",
        "\n",
        "def test_model(model, device, test_dataset, batch_size=1, run_tests=True, time_test_iterations=1000, show_confusion_matrix=True, test_time=True):\n",
        "\n",
        "    if(run_tests and show_confusion_matrix):\n",
        "        confusion_matrix_metric = MulticlassConfusionMatrix(num_classes=len(test_dataset.classes))\n",
        "\n",
        "    if(run_tests):\n",
        "        precision_metric = MulticlassPrecision(average='weighted', num_classes=len(test_dataset.classes))\n",
        "        recall_metric = MulticlassRecall(average='weighted', num_classes=len(test_dataset.classes))\n",
        "        f1score_metric = MulticlassF1Score(average='weighted', num_classes=len(test_dataset.classes))\n",
        "\n",
        "    model.eval()\n",
        "    model.to(device)\n",
        "\n",
        "    test_dataloader = DataLoader(test_dataset, batch_size=batch_size, shuffle=True, num_workers=1)\n",
        "\n",
        "    if(run_tests):\n",
        "        progress_bar = tqdm(total=len(test_dataloader))\n",
        "        for test_data in test_dataloader:\n",
        "            test_inputs, test_labels = test_data\n",
        "            test_inputs = test_inputs.to(device)\n",
        "            test_labels = test_labels.to(device)\n",
        "            test_outputs = model(test_inputs)\n",
        "            output_labels = []\n",
        "\n",
        "            for j in range(0, test_outputs.size()[0]):\n",
        "                probabilities = torch.nn.functional.softmax(test_outputs[j], dim=0)\n",
        "                prob, det_class = torch.topk(probabilities, 1)\n",
        "                # If the detected class is outside of bounds, give a wrong result within bounds\n",
        "                if(det_class >= len(test_dataset.classes)):\n",
        "                    det_class = test_labels[j].item()-1\n",
        "                    if(det_class < 0):\n",
        "                        det_class = test_labels[j].item()+1\n",
        "                output_labels.append(det_class)\n",
        "\n",
        "            output_labels = torch.as_tensor(output_labels)\n",
        "            output_labels.to(device)\n",
        "\n",
        "            confusion_matrix_metric.update(output_labels, test_labels)\n",
        "            precision_metric.update(output_labels, test_labels)\n",
        "            recall_metric.update(output_labels, test_labels)\n",
        "            f1score_metric.update(output_labels, test_labels)\n",
        "\n",
        "            del test_inputs, test_labels\n",
        "\n",
        "            progress_bar.update(1)\n",
        "\n",
        "        precision = precision_metric.compute().item()\n",
        "        recall = recall_metric.compute().item()\n",
        "        f1score = f1score_metric.compute().item()\n",
        "\n",
        "        if(show_confusion_matrix):\n",
        "            confusion_matrix_dataframe = pd.DataFrame(confusion_matrix_metric.normalized(),\n",
        "                                                      index = test_dataset.classes,\n",
        "                                                      columns = test_dataset.classes)\n",
        "            plt.figure(figsize = (16,12))\n",
        "            ax = sn.heatmap(confusion_matrix_dataframe, annot=True, cmap = 'YlOrBr')\n",
        "            ax.xaxis.tick_top()\n",
        "            ax.set_xticks(range(1, len(test_dataset.classes)+1), test_dataset.classes, rotation=270, ha='right');\n",
        "\n",
        "    else:\n",
        "        precision = 0.0\n",
        "        recall = 0.0\n",
        "        f1score = 0.0\n",
        "\n",
        "\n",
        "    # Como o Colab possui um tempo de execução muito variável,\n",
        "    # o tempo pode ser definido como constante, usando um dos valores testados.\n",
        "    average_time = 0.00565 # Resnet 50, 160x160\n",
        "\n",
        "    if(test_time):\n",
        "        model_input, _ = next(iter(test_dataloader))\n",
        "        model_input = model_input.to(device)\n",
        "\n",
        "        total_time = 0\n",
        "        for i in range(time_test_iterations):\n",
        "            t0 = datetime.now()\n",
        "            outputs = model(model_input)\n",
        "            t1 = datetime.now()\n",
        "            total_time += (t1-t0).total_seconds()\n",
        "\n",
        "        del model_input\n",
        "\n",
        "        average_time = total_time/time_test_iterations\n",
        "\n",
        "    final_score = 10*f1score*math.pow(1-average_time, 2)\n",
        "\n",
        "    return final_score, {\"average_time\": average_time, \"f1score\": f1score, \"precision\": precision, \"recall\": recall}"
      ],
      "metadata": {
        "id": "Cv1pSwQI3Vmu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "best_model = torch.hub.load('pytorch/vision:v0.10.0', 'resnet50')\n",
        "best_model.load_state_dict(torch.load(f'model_{timestamp}_best'))\n",
        "\n",
        "test_results = test_model(model=best_model,\n",
        "                          device=device,\n",
        "                          test_dataset=validation_dataset,\n",
        "                          batch_size=1,\n",
        "                          run_tests=True,\n",
        "                          time_test_iterations=1000,\n",
        "                          show_confusion_matrix=True)\n",
        "\n",
        "print(f\"Test data for model:\")\n",
        "print(f\"  '-> Final Score: {test_results[0]}\")\n",
        "print(f\"      |-> Average Time: {test_results[1]['average_time']}\")\n",
        "print(f\"      '-> F1 Score:     {test_results[1]['f1score']}\")\n",
        "print(f\"          |-> Precision: {test_results[1]['precision']}\")\n",
        "print(f\"          '-> Recall:    {test_results[1]['recall']}\")\n"
      ],
      "metadata": {
        "id": "tHYaVKZk3q8-"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}